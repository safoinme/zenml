{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/whylogs_data_profiling/whylogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Data Logging, Profiling and Visualization With Whylogs\n",
    "\n",
    "Data logging and profiling is an important part of any production ML\n",
    "pipeline. [whylogs](https://whylabs.ai/whylogs) is an open source library\n",
    "that analyzes your data and creates statistical summaries called whylogs\n",
    "profiles. whylogs profiles can be visualized locally or uploaded to the\n",
    "[WhyLabs](https://whylabs.ai/) platform where more comprehensive analyses can be carried out.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "ZenML integrates seamlessly with whylogs and WhyLabs. This example shows\n",
    "how easy it is to enhance steps in an existing ML pipeline with whylogs\n",
    "profiling features. Changes to the user code are minimal while ZenML takes\n",
    "care of all aspects related to whylogs serialization, versioning and persistence\n",
    "and even uploading generated profiles to WhyLabs.\n",
    "\n",
    "The ZenML whylogs integration includes the following features showcased in this\n",
    "example:\n",
    "\n",
    "* a predefined `WhylogsProfilerStep` ZenML step class that can be\n",
    "instantiated and inserted into any pipeline to generate a whylogs profile\n",
    "out of a Pandas DataFrame and return the profile as a step output artifact.\n",
    "Instantiating this type of step is simplified even further through the\n",
    "use of the `whylogs_profiler_step` utility function.\n",
    "* a `WhylogsVisualizer` ZenML visualizer that can be used to display whylogs\n",
    "profile artifacts produced during the execution of pipelines.\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run\n",
    "it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/whylogs_data_profiling/whylogs.ipynb)\n",
    "or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/whylogs_data_profiling) directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool, Whylogs and scikit-learn\n",
    "\n",
    "!pip install zenml \n",
    "!zenml integration install -y whylogs sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create a ZenML repository for this project by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1"
   },
   "outputs": [],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to have a whylogs Data Validator component to your stack to be able to use whylogs data profiling in your ZenML pipelines. Creating such a stack is easily accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!zenml data-validator register whylogs -f whylogs\n",
    "!zenml stack register whylogs_stack -o default -a default -dv whylogs --set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvFo9epOUE7G",
    "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import whylogs as why\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from zenml.integrations.constants import SKLEARN, WHYLOGS\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import step, Output\n",
    "\n",
    "from whylogs.core import DatasetProfileView\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps, with the exception of the whylogs data profiling built-in step that is shipped with ZenML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is a `data_loader` step that downloads the diabetes tabular dataset and returns it as a panda DataFrame. The step also generates and returns a whylogs profile out of the entire dataset before splitting it in a subsequent step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VT_PAW10jbp",
    "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
   },
   "outputs": [],
   "source": [
    "os.environ[\"ZENML_ANALYTICS_OPT_IN\"] = \"false\"\n",
    "\n",
    "@step\n",
    "def data_loader() -> Output(\n",
    "    data=pd.DataFrame,\n",
    "    profile=DatasetProfileView,\n",
    "):\n",
    "    \"\"\"Load the diabetes dataset.\"\"\"\n",
    "    X, y = datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "    # merge X and y together\n",
    "    df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "    profile = why.log(pandas=df).profile().view()\n",
    "    return df, profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `data_splitter` step that takes the input dataset and splits it into a training and a validation subset. Later on, in the pipeline, we'll use the builtin whylogs profiler step to generate profiles for both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEw7Cbqx0wXj",
    "outputId": "0603fa51-eb20-4c22-d499-9e7f1f3a972b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "@step\n",
    "def data_splitter(\n",
    "    input: pd.DataFrame,\n",
    ") -> Output(train=pd.DataFrame, test=pd.DataFrame,):\n",
    "    \"\"\"Splits the input dataset into train and test slices.\"\"\"\n",
    "    train, test = train_test_split(input, test_size=0.1, random_state=13)\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two instances of the builtin whylogs profiler step to generate profiles for the test and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.whylogs.steps import WhylogsProfilerParameters, whylogs_profiler_step\n",
    "\n",
    "train_data_profiler = whylogs_profiler_step(\n",
    "    step_name=\"train_data_profiler\",\n",
    "    params=WhylogsProfilerParameters(),\n",
    "    dataset_id=\"model-2\",\n",
    ")\n",
    "test_data_profiler = whylogs_profiler_step(\n",
    "    step_name=\"test_data_profiler\",\n",
    "    params=WhylogsProfilerParameters(),\n",
    "    dataset_id=\"model-3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "from zenml.config import DockerSettings\n",
    "\n",
    "docker_settings = DockerSettings(required_integrations=[SKLEARN, WHYLOGS])\n",
    "\n",
    "\n",
    "@pipeline(settings={\"docker\": docker_settings})\n",
    "def data_profiling_pipeline(\n",
    "    data_loader,\n",
    "    data_splitter,\n",
    "    train_data_profiler,\n",
    "    test_data_profiler,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    data, _ = data_loader()\n",
    "    train, test = data_splitter(data)\n",
    "    train_data_profiler(train)\n",
    "    test_data_profiler(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline. Note how we use the builtin whylogs profiler steps to generate whylogs profiles out of the test and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6"
   },
   "outputs": [],
   "source": [
    "pipeline_instance = data_profiling_pipeline(\n",
    "    data_loader=data_loader(),\n",
    "    data_splitter=data_splitter(),\n",
    "    train_data_profiler=train_data_profiler,\n",
    "    test_data_profiler=test_data_profiler,\n",
    ")\n",
    "pipeline_instance.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post execution workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All whylogs profiles generated by the pipeline run have been versioned, serialized and stored in the ZenML Artifact Store, alongside all other artifacts. The builtin whylogs Materializer included in the whylogs integration took care of that. These artifacts can be extracted and visualized after the pipeline run is complete. The ZenML whylogs visualizer takes in a ZenML pipeline step run and renders all the plots associated with the dataset profile that was generated during its execution. It can also take in two dataset profiles and generate a data drift report visualization.\n",
    "\n",
    "The following is just a helper function to help with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.whylogs.visualizers import WhylogsVisualizer\n",
    "from zenml.logger import get_logger\n",
    "from zenml.post_execution import get_pipeline\n",
    "\n",
    "def visualize_statistics(\n",
    "    step_name: str, reference_step_name: str = None\n",
    ") -> None:\n",
    "    \"\"\"Helper function to visualize whylogs statistics from step artifacts.\n",
    "\n",
    "    Args:\n",
    "        step_name: step that generated and returned a whylogs profile\n",
    "        reference_step_name: an optional second step that generated a whylogs\n",
    "            profile to use for data drift visualization where two whylogs\n",
    "            profiles are required.\n",
    "    \"\"\"\n",
    "    pipe = get_pipeline(pipeline=\"data_profiling_pipeline\")\n",
    "    whylogs_step = pipe.runs[-1].get_step(step=step_name)\n",
    "    whylogs_reference_step = None\n",
    "    if reference_step_name:\n",
    "        whylogs_reference_step = pipe.runs[-1].get_step(\n",
    "            name=reference_step_name\n",
    "        )\n",
    "\n",
    "    WhylogsVisualizer().visualize(\n",
    "        whylogs_step,\n",
    "        reference_step_view=whylogs_reference_step,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the helper function to render two dashboards:\n",
    "\n",
    "* a visualization of the profile generated for the entire dataset in the loader step\n",
    "* a data drift visualization rendered from the two profiles we created from the test/validation slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_statistics(\"data_loader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_statistics(\"train_data_profiler\", \"test_data_profiler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "You have successfully used ZenML and whylogs to generate data profiles and visualize data drift reports.\n",
    "\n",
    "For more ZenML features and use-cases, you should check out some of the other ZenML examples. You should also take a look at our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) repo, or even better, join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('zenml-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "92bd632b13ad08a98e6c591fb282887679d737095c495564873743f0fe7001fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
