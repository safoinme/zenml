{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML: Create production-ready ML pipelines\n",
    "\n",
    "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML. We will start local in the jupyter notebook but will transition over to a more robust environment with Kubeflow pipelines.\n",
    "\n",
    "This guide is designed to provide a practical introduction to transitioning from local setup to a more production MLOps stack. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![zenml](assets/zenml.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "b413e26c-e610-4803-e39b-55906cb1f31b"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool and Tensorflow\n",
    "!pip install zenml\n",
    "!zenml integration install kubeflow tensorflow tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "fea5770a-d7de-4169-893c-eae2aa97f517"
   },
   "outputs": [],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with the local stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "The above commands have automatically created a local MLOps stack for you and set it to active. Let's make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![localstack.png](assets/localstack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Create your first pipeline with the local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "Let's first do the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvFo9epOUE7G"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from zenml.integrations.constants import TENSORFLOW\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import BaseParameters, Output, StepContext, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is an `importer` step that downloads a sample of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VT_PAW10jbp"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray,\n",
    "    X_test=np.ndarray,\n",
    "    y_train=np.ndarray,\n",
    "    y_test=np.ndarray,\n",
    "):\n",
    "    \"\"\"Download the MNIST data store it as an artifact\"\"\"\n",
    "    (X_train, y_train), (\n",
    "        X_test,\n",
    "        y_test,\n",
    "    ) = tf.keras.datasets.mnist.load_data()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Then we add a `normalizer` step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def normalizer(\n",
    "    X_train: np.ndarray, X_test: np.ndarray\n",
    ") -> Output(X_train_normed=np.ndarray, X_test_normed=np.ndarray):\n",
    "    \"\"\"Normalize digits dataset with mean and standard deviation.\"\"\"\n",
    "    X_train_normed = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "    X_test_normed = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "    return X_train_normed, X_test_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `trainer` step, that takes the normalized data and trains a Keras model on the data. The step has an associated `TrainerConfig` step configuration class. Also note how we use the `StepContext` to extract the Artifact Store path alongside the output model Artifact where TensorBoard logs are to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEw7Cbqx0wXj"
   },
   "outputs": [],
   "source": [
    "class TrainerParameters(BaseParameters):\n",
    "    \"\"\"Trainer params\"\"\"\n",
    "\n",
    "    epochs: int = 1\n",
    "    lr: float = 0.001\n",
    "\n",
    "@step\n",
    "def trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    context: StepContext,\n",
    "    params: TrainerParameters,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Train a neural net from scratch to recognize MNIST digits return our\n",
    "    model or the learner\"\"\"\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    log_dir = os.path.join(context.get_output_artifact_uri(), \"logs\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(params.lr),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=params.epochs,\n",
    "        callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we had an `evaluator` to see how we did on the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: tf.keras.Model,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    logging.info(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def mnist_pipeline(\n",
    "    importer,\n",
    "    normalizer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    # Link all the steps together\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    X_trained_normed, X_test_normed = normalizer(X_train=X_train, X_test=X_test)\n",
    "    model = trainer(X_train=X_trained_normed, y_train=y_train)\n",
    "    evaluator(X_test=X_test_normed, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "f61e4408-4001-4cc7-ed7d-8472b1c4089f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "first_pipeline = mnist_pipeline(\n",
    "    importer=importer(),\n",
    "    normalizer=normalizer(),\n",
    "    trainer=trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "\n",
    "first_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Visualize the model with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "To visualize the model with TensorBoard, make use of the built-in ZenML TensorBoard visualizer, that will automatically start a TensorBoard server in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "f61e4408-4001-4cc7-ed7d-8472b1c4089f"
   },
   "outputs": [],
   "source": [
    "from zenml.integrations.tensorboard.visualizers import (\n",
    "    visualize_tensorboard,\n",
    "    stop_tensorboard_server,\n",
    ")\n",
    "\n",
    "visualize_tensorboard(\n",
    "    pipeline_name=\"mnist_pipeline\",\n",
    "    step_name=\"trainer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the TensorBoard server, you can use the `stop_tensorboard` utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_tensorboard_server(\n",
    "    pipeline_name=\"mnist_pipeline\",\n",
    "    step_name=\"trainer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gotkJdTQz8j2"
   },
   "source": [
    "# Transitioning to Kubeflow Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMLU4cNW-Ei4"
   },
   "source": [
    "We got pretty good results on the digits model that we trained, but at some point we want to get out of this notebook local stack and go to a stack which looks more like production. Here is where the ZenML [Kubeflow Pipelines](https://github.com/kubeflow/pipelines) integration helps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this example, you need to have installed:\n",
    "\n",
    "* [Docker](https://docs.docker.com/get-docker/)\n",
    "* [K3D](https://k3d.io/v5.2.1/) \n",
    "* [Kubectl](https://kubernetes.io/docs/tasks/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Kubeflow Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![localstack-with-kubeflow.png](assets/localstack-with-kubeflow-orchestrator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml container-registry register local_registry --uri=localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml orchestrator register kubeflow_orchestrator --flavor=kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack register local_kubeflow_stack -a default -o kubeflow_orchestrator -c local_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack set local_kubeflow_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets spin the stack up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the pipeline to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run-kubeflow.py\n",
    "#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at:\n",
    "#\n",
    "#       https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n",
    "#  or implied. See the License for the specific language governing\n",
    "#  permissions and limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from zenml.integrations.constants import TENSORFLOW\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import BaseParameters, Output, StepContext, step\n",
    "from zenml.config import DockerSettings\n",
    "\n",
    "\n",
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray,\n",
    "    X_test=np.ndarray,\n",
    "    y_train=np.ndarray,\n",
    "    y_test=np.ndarray,\n",
    "):\n",
    "    \"\"\"Download the MNIST data store it as an artifact\"\"\"\n",
    "    (X_train, y_train), (\n",
    "        X_test,\n",
    "        y_test,\n",
    "    ) = tf.keras.datasets.mnist.load_data()\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "@step\n",
    "def normalizer(\n",
    "    X_train: np.ndarray, X_test: np.ndarray\n",
    ") -> Output(X_train_normed=np.ndarray, X_test_normed=np.ndarray):\n",
    "    \"\"\"Normalize digits dataset with mean and standard deviation.\"\"\"\n",
    "    X_train_normed = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "    X_test_normed = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "    return X_train_normed, X_test_normed\n",
    "\n",
    "\n",
    "class TrainerParameters(BaseParameters):\n",
    "    \"\"\"Trainer params\"\"\"\n",
    "\n",
    "    epochs: int = 1\n",
    "    lr: float = 0.001\n",
    "\n",
    "\n",
    "@step\n",
    "def trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    context: StepContext,\n",
    "    params: TrainerParameters,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Train a neural net from scratch to recognize MNIST digits return our\n",
    "    model or the learner\"\"\"\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    log_dir = os.path.join(context.get_output_artifact_uri(), \"logs\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(params.lr),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=params.epochs,\n",
    "        callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: tf.keras.Model,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    logging.info(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "docker_settings = DockerSettings(required_integrations=[TENSORFLOW])\n",
    "\n",
    "@pipeline(enable_cache=True, settings={\"docker\": docker_settings})\n",
    "def mnist_pipeline(\n",
    "    importer,\n",
    "    normalizer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    # Link all the steps together\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    X_trained_normed, X_test_normed = normalizer(X_train=X_train, X_test=X_test)\n",
    "    model = trainer(X_train=X_trained_normed, y_train=y_train)\n",
    "    evaluator(X_test=X_test_normed, y_test=y_test, model=model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the pipeline\n",
    "    pipeline_instance = mnist_pipeline(\n",
    "        importer=importer(),\n",
    "        normalizer=normalizer(),\n",
    "        trainer=trainer(),\n",
    "        evaluator=evaluator(),\n",
    "    )\n",
    "    pipeline_instance.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new pipeline\n",
    "!python run-kubeflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uKNmljpIYRh"
   },
   "source": [
    "# Post execution workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5yPNQ1fIYRh"
   },
   "outputs": [],
   "source": [
    "from zenml.post_execution import get_pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-rao3-oIYRj"
   },
   "source": [
    "## Pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxMk-vsmIYRk"
   },
   "outputs": [],
   "source": [
    "pipelines = get_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFd--JgZIYRk"
   },
   "source": [
    "## Retrieve the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BSbKed-IYRk"
   },
   "outputs": [],
   "source": [
    "mnist_pipeline = pipelines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpNKuyChIYRl"
   },
   "source": [
    "## Get the first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI57bWbHIYRl"
   },
   "outputs": [],
   "source": [
    "runs = mnist_pipeline.runs  # chronologically ordered\n",
    "mnist_run = runs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIPmpQCrIYRl"
   },
   "source": [
    "## Get the second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SGaTPduIYRl"
   },
   "outputs": [],
   "source": [
    "kubeflow_mnist_run = runs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDR1JNHtIYRm"
   },
   "source": [
    "## Get the steps (note the first step name is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vct_wqq1IYRm",
    "outputId": "7800431d-813b-4721-f61d-27f4012f9d2d"
   },
   "outputs": [],
   "source": [
    "mnist_run.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnQkTAv6IYRm",
    "outputId": "8fedfaf1-b5c9-4218-809c-244b8f6ebc2c"
   },
   "outputs": [],
   "source": [
    "kubeflow_mnist_run.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m6d6VPDIYRn"
   },
   "source": [
    "## Check the results of the evaluator and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sF7YM4_iIYRn"
   },
   "outputs": [],
   "source": [
    "mnist_eval_step = mnist_run.get_step(step='evaluator')\n",
    "kubeflow_mnist_eval_step = kubeflow_mnist_run.get_step(step='evaluator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5fvkLoZIYRn",
    "outputId": "a8d0ad4d-bbd0-4320-a282-870120ac3ddf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One output is simply called `output`, multiple is a dict called `outputs`.\n",
    "mnist_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMBKfBSeIYRo",
    "outputId": "4387f938-bb21-492e-9c90-79a8b4329101"
   },
   "outputs": [],
   "source": [
    "kubeflow_mnist_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tan15BgIYRo"
   },
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "… and that's it!. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. You have also deployed said pipeline to a production MLOps stack from right within your notebook! Hurray!\n",
    "\n",
    "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) or even better join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22gkBKSntlF8"
   },
   "source": [
    "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "92bd632b13ad08a98e6c591fb282887679d737095c495564873743f0fe7001fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
