# ‚è≠ Gradient Boosting with XGBoost and ZenML

[XGBoost](https://xgboost.readthedocs.io/en/latest/) is an optimized 
distributed gradient boosting library designed to be highly efficient, flexible 
and portable. It implements machine learning algorithms under the Gradient 
Boosting framework. XGBoost provides a parallel tree boosting (also known as 
GBDT, GBM) that solve many data science problems in a fast and accurate way.

This example showcases how to train a `XGBoost Booster` model in a ZenML 
pipeline. The ZenML `XGBoost` integration includes a custom materializer that 
persists the trained `xgboost.Booster` model to and from the artifact store. 
It also includes materializers for the custom `XGBoost.DMatrix` data object.

The data used in this example is the quickstart XGBoost data and is available in
the [demo directory of the XGBoost repository](https://github.com/dmlc/xgboost/tree/master/demo/data).

## üñ• Run it locally

## ‚è© SuperQuick `xgboost` run

If you're really in a hurry and just want to see this example pipeline run
without wanting to fiddle around with all the individual installation and
configuration steps, just run the following:

```shell
zenml example run xgboost
```

## üë£ Step-by-Step

### üìÑ Prerequisites

In order to run this example, you need to install and initialize ZenML:

```shell
# install CLI
pip install "zenml[server]"

# install ZenML integrations
zenml integration install xgboost

# pull example
zenml example pull xgboost
cd zenml_examples/xgboost

# initialize
zenml init

# Start the ZenServer to enable dashboard access
zenml up
```

### ‚ñ∂Ô∏è Run the Code

Now we're ready. Execute:

```shell
python run.py
```

### üßΩ Clean up

In order to clean up, delete the remaining ZenML references.

```shell
rm -rf zenml_examples
```
